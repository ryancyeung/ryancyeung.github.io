<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Ryan C. Yeung </title> <meta name="author" content="Ryan C. Yeung"> <meta name="description" content="Personal academic homepage for Ryan C. Yeung. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?fd3f379a58f61eb6022a2a3cc07a79df"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ryancyeung.github.io/publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ryan</span> C. Yeung </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/hobbies/">hobbies </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p><strong>17</strong> peer-reviewed publications (<strong>14</strong> as first author).</p> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sokolowski2026visual" class="col-sm-8"> <div class="title">Visual imagery and STEM occupational attainment: Gender matters</div> <div class="author"> H Moriah Sokolowski, <em>Ryan C Yeung</em>, Ju-Chi Yu, Carina L Fan, Richard Daker, Ian Lyons, Adam Zeman, Hervé Abdi, and Brian Levine </div> <div class="periodical"> <em>Personality and Individual Differences</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1016/j.paid.2025.113552" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> </div> <div class="abstract hidden"> <p>Science, technology, engineering and mathematical (STEM) occupations are widely recognized as important for innovation and economic growth, yet there is a STEM labour shortage, particularly among women. We examined how individual differences in visual imagery relate to characteristics of STEM occupations using a novel coding scheme for the dimensional quantification of occupational attributes. In a discovery cohort of 4545 online participants, we found that spatial thinking positively associated with STEM occupations across genders. Object imagery (mnemonic vividness), however, was negatively associated with STEM occupations that require computational processes, such as software engineers. This negative association was present for males, but not females. We extended and replicated these findings in samples of 1891 individuals with aphantasia (congenitally low imagery) and 186 university undergraduates. Consistent with experimental, observational, and neurobiological evidence of a potentially competitive relationship between imagery and reasoning, these results suggest a role for nonspatial, nonvisual abstract analytic abilities in computational STEM disciplines independent of spatial imagery. These abilities promote computational STEM achievement in males but not females, who may be biased away for social reasons. Visual imagery style could serve as a marker of STEM potential, and selection into computational STEM may draw on skills distinct from other STEM fields.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2026voluntary" class="col-sm-8"> <div class="title">Voluntary and recurrent involuntary autobiographical memories: Similar phenomenology, different relationships with psychopathology</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Journal of Applied Research in Memory and Cognition</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1037/mac0000261" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/CNZS7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Recurrent involuntary autobiographical memories (rIAMs) may be a transdiagnostic feature of psychopathology, since their phenomenology (subjective experience; e.g., negative valence, high vividness) could impact mental health. However, it remains unclear whether rIAM phenomenology is uniquely associated with psychopathology, or if these associations extend to voluntary AMs (VAMs). Here, we analyzed VAMs (n = 871) and rIAMs (n = 2,101) produced by undergraduates, contrasting univariate and multivariate approaches of relating AM phenomenology to psychopathology. Despite overall similarities across AM types, rIAM phenomenology (e.g., negative valence, high emotional intensity) distinguished between participants with versus without disorders, whereas VAMs could not, even if they had comparable phenomenology. Furthermore, rIAM phenomenology provided significantly better estimates of posttraumatic stress disorder and general anxiety symptoms than VAM phenomenology, suggesting some disorder-specificity. rIAMs have unique transdiagnostic relationships with psychopathology, to a greater extent than VAMs.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2025curse" class="col-sm-8"> <div class="title">The curse of imagery: Trait object and spatial imagery differentially relate to symptoms of posttraumatic stress disorder</div> <div class="author"> <em>Ryan C Yeung</em>, H Moriah Sokolowski, Carina L Fan, Myra A Fernandes, and Brian Levine </div> <div class="periodical"> <em>Clinical Psychological Science</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1177/21677026251315118" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/FSRHM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Imagery is integral to autobiographical memory (AM). Past work has highlighted the benefits of high trait imagery on episodic AM, including faster, more detailed, and more vivid retrieval. However, these advantages may come with drawbacks: Following potentially traumatic events, strong visual imagery could promote the intrusions characteristic of posttraumatic stress disorder (PTSD). Conversely, spatial imagery could schematize potentially traumatic events, countering vivid recollection and reducing distress. We examined relationships between trait object imagery (e.g., color, shape), spatial imagery (e.g., abstract representations, locations), and PTSD symptoms in two independent samples: trauma-exposed adults (n = 806) and undergraduates (n = 493). As predicted, higher object imagery was associated with more PTSD symptoms in both samples. Higher spatial-schematic processing was associated with fewer PTSD symptoms in the trauma-exposed sample, although this effect was confined to men in the undergraduate sample. Different forms of imagery have different—or even opposing—relationships with episodic AM that affect PTSD symptoms.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tanberg2025evidence" class="col-sm-8"> <div class="title">Evidence of temporal and emotional alignment between song cues and their evoked autobiographical memories</div> <div class="author"> Pelin Tanberg<sup>*</sup>, <em>Ryan C Yeung<sup>*</sup></em>, and Myra A Fernandes <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution, co-first authorship."> </i> </div> <div class="periodical"> <em>Memory &amp; Cognition</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.3758/s13421-025-01717-w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/QK6U5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Hearing music can evoke vivid memories from one’s past. Here, we examined how musical versus verbal features of pop songs influenced retrieval of autobiographical memories (AMs) and explored mechanisms of action. We first compared the quantity and quality of AMs evoked by musical cues (popular songs) versus matched nonmusical cues (spoken lyrics). On each trial, participants (N = 84) listened to an auditory cue, which was either musical (a song clip) or spoken (a computer-generated neutral voice reading the lyrics from the song clip). While listening, participants indicated via button press whether the cue evoked an AM – if so, they described the AM in text, then rated the AM’s properties (e.g., age of the memory, feelings of reliving, cue familiarity). We found that song cues were significantly more likely to evoke AMs (M = 49%) than spoken cues (M = 33%), even when controlling for cue familiarity. Song cues also elicited significantly greater feelings of reliving the evoked AM, compared to spoken cues, though this effect disappeared after controlling for cue familiarity. Critically, we found evidence of temporal and emotional alignment between cues and their evoked AMs: older cues (e.g., songs released in 2017 vs. 2020) evoked older AMs, and more positive cues (e.g., songs of higher valence, as derived from Spotify audio features) evoked AMs with more positive content (as derived from sentiment analysis). Findings suggest that song cues enhance AM accessibility by setting the temporal and emotional contexts for retrieval.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2024disentangling" class="col-sm-8"> <div class="title">Disentangling boredom from depression using the phenomenology and content of involuntary autobiographical memories</div> <div class="author"> <em>Ryan C Yeung</em>, James Danckert, Wijnand AP Van Tilburg, and Myra A Fernandes </div> <div class="periodical"> <em>Scientific Reports</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1038/s41598-024-52495-5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/83Y2R" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Recurrent involuntary autobiographical memories (IAMs) are memories retrieved unintentionally and repetitively. We examined whether the phenomenology and content of recurrent IAMs could differentiate boredom and depression, both of which are characterized by affective dysregulation and spontaneous thought. Participants (n = 2484) described their most frequent IAM and rated its phenomenological properties (e.g., valence). Structural topic modeling, a method of unsupervised machine learning, identified coherent content within the described memories. Boredom proneness was positively correlated with depressive symptoms, and both boredom proneness and depressive symptoms were correlated with more negative recurrent IAMs. Boredom proneness predicted less vivid recurrent IAMs, whereas depressive symptoms predicted more vivid, negative, and emotionally intense ones. Memory content also diverged: topics such as relationship conflicts were positively predicted by depressive symptoms, but negatively predicted by boredom proneness. Phenomenology and content in recurrent IAMs can effectively disambiguate boredom proneness from depressive symptoms in a large sample of undergraduate students from a racially diverse university.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2024recurrent" class="col-sm-8"> <div class="title">Recurrent involuntary memories and mind wandering are related but distinct</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Psychological Research</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1007/s00426-024-01961-w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/8AQMV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Spontaneous thought is common in daily life, and includes recurrent involuntary autobiographical memories (IAMs; memories retrieved unintentionally and repetitively) and mind wandering (MW). Both recurrent IAMs and MW are often unintentional or unconstrained, and both predict symptoms of mental health disorders. However, not all MW is unintentional, and not all IAMs are unconstrained. To what extent do recurrent IAMs and MW converge versus diverge? Undergraduates (N = 2,701) completed self-report measures of recurrent IAMs, trait MW, and psychopathology (i.e., PTSD, depression, anxiety). Regressions indicated that recurrent IAMs were significantly associated with spontaneous MW, but not deliberate MW. Further, both spontaneous MW and recurrent IAMs had unique relationships with disorder symptoms. Results suggest that recurrent IAMs are related to MW to the extent that recurrent IAMs are spontaneous. Conversely, recurrent IAMs are distinct from MW to the extent that recurrent IAMs’ associations with disorder symptoms could not be solely explained by trait MW (and vice versa). This work highlights related, but distinguishable, forms of spontaneous thought and their transdiagnostic links with psychopathology.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zaza2024evaluating" class="col-sm-8"> <div class="title">Evaluating the impacts of an undergraduate mental health literacy course</div> <div class="author"> Christine Zaza, <em>Ryan C Yeung</em>, and Gitanjali Shanbhag </div> <div class="periodical"> <em>The Canadian Journal for the Scholarship of Teaching and Learning</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.5206/cjsotlrcacea.2024.3.16349" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> </div> <div class="abstract hidden"> <p>Mental health literacy is an important factor in caring for mental health; however, in the post-secondary student population, mental health literacy is reported to be low. To address these issues, in 2020, one of the authors [CZ] developed an undergraduate mental health literacy (MHL) course offered through the Faculty of Health, University of Waterloo, to undergraduate students in all Faculties. Building on promising early research conducted by two of the authors in 2021, we conducted three studies to evaluate the impacts of the fully online version of this MHL course. Study #1 was a pre-post study to examine knowledge and attitudes related to mental health literacy (n = 162). Study #2 was a one-month follow-up study to assess continued use of mental wellness strategies practiced during the course (n = 18), and study #3 was a content analysis of part one of the final reflection assignment of the course (n = 32). The pre-post study did not reveal any meaningful changes in knowledge and attitude from Time 1 to Time 2. However, the one-month follow-up study and the content analysis of the final reflection assignment showed multiple meaningful and positive shifts in knowledge, attitudes, and behaviours related to mental health, stigma, self-care, well-being, supporting others with mental health concerns, and the meaning of resilience. In addition, the content analysis revealed that students were sharing course resources with peers, friends, family members and with their community at large. In addition to guiding revisions to strengthen the MHL course under investigation, our findings are relevant to other MHL education initiatives in this population.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zaza2023s" class="col-sm-8"> <div class="title">It’s time to bring mental health literacy education into the postsecondary curriculum</div> <div class="author"> Christine Zaza and <em>Ryan C Yeung</em> </div> <div class="periodical"> <em>Canadian Journal for the Scholarship of Teaching and Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.5206/cjsotlrcacea.2023.1.13663" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://osf.io/a9yw2/?view_only=679c92db44af42e68df21d4cca500fdb" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>In the last twenty years, research on post-secondary students’ mental health and well-being has grown substantially, with a dramatic increase in publications over the past decade. Likewise, concerns about declining mental health on our campuses have risen; the mental well-being of postsecondary students is now widely recognized as a major public health issue. Over the last two decades, Canadian higher education has largely addressed these concerns by promoting mental health awareness through extracurricular means. Critically, a new movement towards mental health literacy has emerged across the nation: not just supplementary outreach, but education embedded into the curriculum. To put recommendations into practice, in 2020, one of the authors [CZ] developed and taught an undergraduate course on mental health literacy with a class of 106 students. In the first offering, we conducted a pre-post study to examine if this new course would be associated with changes in mental health knowledge, stigma, and help-seeking. Of the forty students who participated in the study, ten completed measures at both the start (T1) and the end of the course (T2). Within-subjects analyses showed that students made significant gains from T1 to T2, with a large effect size, in terms of attitudes toward seeking mental health services. Feedback on the course was very positive, both in students’ ratings and their comments. Looking ahead, student well-being will depend on how institutions approach and engage with mental health literacy. We recommend firmly integrating mental health literacy education into the post-secondary curriculum.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2023specific" class="col-sm-8"> <div class="title">Specific topics, specific symptoms: Linking the content of recurrent involuntary memories to mental health using computational text analysis</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>npj Mental Health Research</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1038/s44184-023-00042-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/GUR5V" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Researchers debate whether recurrent involuntary autobiographical memories (IAMs; memories of one’s personal past retrieved unintentionally and repetitively) are pathological or ordinary. While some argue that these memories contribute to clinical disorders, recurrent IAMs are also common in everyday life. Here, we examined how the content of recurrent IAMs might distinguish between those that are maladaptive (related to worse mental health) versus benign (unrelated to mental health). Over two years, 6187 undergraduates completed online surveys about recurrent IAMs; those who experienced recurrent IAMs within the past year were asked to describe their memories, resulting in 3624 text descriptions. Using a previously validated computational approach (structural topic modeling), we identi ed coherent topics (e.g., “Conversations” , “Experiences with family members”) in recurrent IAMs. Specific topics (e.g., “Negative past relationships”, “Abuse and trauma”) were uniquely related to symptoms of mental health disorders (e.g., depression, PTSD), above and beyond the self-reported valence of these memories. Importantly, we also found that content in recurrent IAMs was distinct across symptom types (e.g., “Communication and miscommunication” was related to social anxiety, but not symptoms of other disorders), suggesting that while negative recurrent IAMs are transdiagnostic, their content remains unique across different types of mental health concerns. Our work shows that topics in recurrent IAMs—and their links to mental health—are identifiable, distinguishable, and quantifiable.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2022machine" class="col-sm-8"> <div class="title">Machine learning to detect invalid text responses: Validation and comparison to existing detection methods</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Behavior Research Methods</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.3758/s13428-022-01801-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/3HS56" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> <a href="https://github.com/ryancyeung/invalid-text-detect" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-code"></i> Code</a> </div> <div class="abstract hidden"> <p>A crucial step in analysing text data is the detection and removal of invalid texts (e.g., texts with meaningless or irrelevant content). To date, research topics that rely heavily on analysis of text data, such as autobiographical memory, have lacked methods of detecting invalid texts that are both effective and practical. Although researchers have suggested many data quality indicators that might identify invalid responses (e.g., response time, character/word count), few of these methods have been empirically validated with text responses. In the current study, we propose and implement a supervised machine learning approach that can mimic the accuracy of human coding, but without the need to hand-code entire text datasets. Our approach (a) trains, validates, and tests on a subset of texts manually labelled as valid or invalid, (b) calculates performance metrics to help select the best model, and (c) predicts whether unlabelled texts are valid or invalid based on the text alone. Model validation and evaluation using autobiographical memory texts indicated that machine learning accurately detected invalid texts with performance near human coding, significantly outperforming existing data quality indicators. Our openly available code and instructions enable new methods of improving data quality for researchers using text as data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2022understanding" class="col-sm-8"> <div class="title">Understanding autobiographical memory content using computational text analysis</div> <div class="author"> <em>Ryan C Yeung</em>, Marek Stastna, and Myra A Fernandes </div> <div class="periodical"> <em>Memory</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1080/09658211.2022.2104317" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/3584C" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Although research on autobiographical memory (AM) continues to grow, there remain few methods to analyze AM content. Past approaches are typically manual, and prohibitively time- and labour-intensive. These methodological limitations are concerning because content may provide insights into the nature and functions of AM. In particular, analyzing content in recurrent involuntary autobiographical memories (IAMs; those that spring to mind unintentionally and repetitively) could resolve controversies about whether these memories typically involve mundane or distressing events. Here, we present computational methods that can analyze content in thousands of participants’ AMs, without needing to hand-code each memory. A sample of 6,187 undergraduates completed surveys about recurrent IAMs, resulting in 3,624 text descriptions. Using frequency analyses, we identified common (e.g., “time” , “friend”) and distinctive words in recurrent IAMs (e.g., “argument” as distinctive to negative recurrent IAMs). Using structural topic modelling, we identified coherent topics (e.g., “Negative past relationships” , “Conversations” , “Experiences with family members”) within recurrent IAMs and found that topic use significantly differed depending on the valence of these memories. Computational methods allowed us to analyze large quantities of AM content with enhanced granularity and reproducibility. We present the means to enable future research on AM content at an unprecedented scope and scale.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2021influence" class="col-sm-8"> <div class="title">The influence of social anxiety-provoking contexts on context reinstatement effects</div> <div class="author"> <em>Ryan C Yeung</em>, Christopher M Lee, and Myra A Fernandes </div> <div class="periodical"> <em>Quarterly Journal of Experimental Psychology</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1177/1747021821998489" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/VGQU5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>The context reinstatement (CR) effect is the finding that target stimuli are better remembered when presented in the same context as during initial encoding, compared with a different context. It remains unclear, however, whether emotional features of the context affect this memory benefit. In two experiments, we investigated whether the anxiety-provoking nature of a context scene might influence the CR effect. During encoding, participants viewed target faces paired with scenes validated as either highly anxiety-provoking or not, half of which contained other faces embedded within the scene. During retrieval, target faces were presented again with either the same or a new context scene. In Experiment 1, the expected CR effect was observed when the contexts were low-anxiety scenes or high-anxiety scenes without embedded faces. In contrast, the CR effect was absent when the contexts were high-anxiety scenes containing embedded faces. In Experiment 2, to determine whether the presence of embedded faces or the anxiety level of scenes reduced the CR effect, we included an additional context type: low-anxiety scenes with embedded faces. Once again, the CR effect was absent only when the context scene was highly anxiety-provoking with embedded faces: reinstating this context type failed to benefit memory for targets. Results suggest that the benefit to target memory via reinstating a context depends critically on emotional characteristics of the reinstated context.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2021divided" class="col-sm-8"> <div class="title">Divided attention at encoding or retrieval interferes with emotionally enhanced memory for words</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Memory</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1080/09658211.2021.1887896" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/4HZMU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Emotional information is typically better remembered than neutral information. We asked whether emotional, compared to neutral, words were less vulnerable to the detrimental effects of divided attention. In two experiments, undergraduate students intentionally encoded words of intermixed valence (neutral, negative, or positive) and arousal (neutral, high, or low). Following a filled delay, memory was assessed with a free recall test. In Experiment 1, participants encoded visually–presented words under either full attention (FA; no distracting task) or divided attention (DA; concurrently making animacy decisions to auditorily–presented distractor words) in a counterbalanced, within–subjects design. As expected following FA at encoding, recall was significantly enhanced for negative compared to neutral words. Following DA at encoding, recall was significantly impaired across all valences. Critically, DA at encoding also eliminated the memory benefit for negative information: recall of negative words was no longer significantly different from neutral or positive words. In Experiment 2, we manipulated attention at retrieval rather than encoding. Remarkably, results from Experiment 1 were replicated: DA eliminated the well-known emotionality boost for negative words. In both experiments, memory for positive words did not significantly differ from neutral. Findings suggest that DA during either encoding or retrieval can interfere with the specific mechanisms by which negative emotion typically improves memory.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2021recurrent" class="col-sm-8"> <div class="title">Recurrent involuntary memories are modulated by age and linked to mental health</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Psychology and Aging</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1037/pag0000630" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/MZNUW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Recurrent involuntary autobiographical memories (IAMs), or memories that spring to mind unintentionally and repetitively, are common among younger and older adults. Since older adults show enhanced emotion regulation, we investigated whether their recurrent IAMs were more positive than younger adults’. Additionally, we examined whether recurrent IAMs reflected mental health in both age groups. In our study, community-dwelling older (Mage = 75.6) and younger adults (Mage = 19.7; ns = 95) completed surveys assessing recurrent IAMs (e.g., their frequency, valence) and symptoms of mental health issues (e.g., depression, anxiety, posttraumatic stress). As hypothesized, age modulated recurrent IAM valence, despite the involuntary nature of these memories: younger adults’ recurrent IAMs were disproportionately negative (74%), whereas older adults’ were disproportionately positive (60%). Further, experiencing recurrent IAMs—especially negative ones—predicted worse mental health in both younger and older adults.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2020recurrent" class="col-sm-8"> <div class="title">Recurrent involuntary autobiographical memories: Characteristics and links to mental health status</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Memory</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1080/09658211.2020.1777312" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/FG6CP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Memories of events from one’s personal past that come to mind unintentionally and effortlessly are termed involuntary autobiographical memories (IAMs). Recurrent IAMs are known as relevant to many disorders within clinical literature. However, less is known about their links with mental health status in the general population. In the current study, 2184 undergraduate students completed surveys assessing occurrence of any recurrent IAMs. Participants also wrote a description of their most frequently recurring IAM and rated it on phenomenological characteristics, such as frequency, valence, vividness, and centrality. Results showed that the majority of our sample experienced recurrent IAMs, replicating previous findings, but most of these memories were emotionally negative, unlike past work. Importantly, negative recurrent IAMs were associated with significantly more mental health concerns, including symptoms of depression, anxiety, and posttraumatic stress. We also found that frequency of IAM recurrence was predicted by the memory’s age, level of completeness/detail, emotional intensity, and centrality to one’s life story. Further, descriptions of positive recurrent IAMs contained significantly more episodic detail compared to negative or neutral ones, suggesting that emotional regulation may play a role in how recurrent IAMs are recounted. Recurrent IAMs, and their characteristics, serve as a window into mental health status.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2019social" class="col-sm-8"> <div class="title">Social anxiety enhances recognition of task-irrelevant threat words</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Acta Psychologica</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1016/j.actpsy.2019.01.015" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> </div> <div class="abstract hidden"> <p>Past research is mixed regarding the conditions under which memory biases emerge in individuals with high levels of social anxiety. The current study examined whether high social anxiety would be associated with a memory bias for threatening, but task-irrelevant information, or whether it creates a memory bias for both threatening as well as neutral distractors. 60 undergraduate students were recruited, half classified as having high social anxiety and half as having low social anxiety according to the Social Phobia Inventory. Participants memorized a series of sequentially and visually presented target words that were either all neutral (e.g., patient) or all socially threatening (e.g., embarrassed). Simultaneously during encoding, participants also saw a distractor word on each trial that was either neutral or socially threatening. Memory for targets was then assessed using a recall and recognition test. Incidental recall and recognition tests for the distractors were also administered. There were no group differences in memory for threat versus neutral targets. However, recognition of socially threatening distractors was significantly enhanced in those with high relative to low levels of social anxiety, but only when targets were also socially threatening. Memory biases in high social anxiety were shown to be specific for threat-related distractors rather than general, for all distractors. This specific bias for threat emerged only when the to-be-remembered target information was also threatening. Findings suggest that when social anxiety is primed, attention to irrelevant, but socially threatening, information is heightened.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yeung2019altered" class="col-sm-8"> <div class="title">Altered working memory capacity for social threat words in high versus low social anxiety</div> <div class="author"> <em>Ryan C Yeung</em> and Myra A Fernandes </div> <div class="periodical"> <em>Anxiety, Stress, &amp; Coping</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1080/10615806.2019.1626838" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-link"></i> DOI</a> <a href="https://doi.org/10.17605/OSF.IO/RVGSJ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="ai ai-osf"></i> OSF</a> </div> <div class="abstract hidden"> <p>Background and objectives: Differences in working memory capacity (WMC) have been suggested in individuals with high levels of social anxiety (SA). Specifically, these individuals may preferentially maintain socially threatening material in working memory. Design and methods: We adapted the digit span task to a series of word span tasks. We assessed WMC for lists of words that varied in terms of their threat-relatedness, in individuals either high or low in SA. Results: Experiment 1 revealed reduced WMC for socially threatening words in those with high compared to low SA. Importantly, this relative reduction in WMC was driven by the low SA group showing expanded capacity for socially threatening words relative to neutral or generally threatening words. Furthermore, reductions in WMC for social threat were uniquely predicted by SA, and not by other theoretically related constructs such as state general anxiety, trait general anxiety, or depression. Experiment 2 showed that the semantic similarity of the words within each list was not responsible for the differences in WMC between list type or SA group. Conclusions: Our findings suggest that individuals high in SA may fail to upregulate WMC for social information due to the activation of, or rumination upon, socially threatening concepts.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ryan C. Yeung. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>